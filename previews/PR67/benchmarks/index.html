<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Benchmarks · NonuniformFFTs</title><meta name="title" content="Benchmarks · NonuniformFFTs"/><meta property="og:title" content="Benchmarks · NonuniformFFTs"/><meta property="twitter:title" content="Benchmarks · NonuniformFFTs"/><meta name="description" content="Documentation for NonuniformFFTs."/><meta property="og:description" content="Documentation for NonuniformFFTs."/><meta property="twitter:description" content="Documentation for NonuniformFFTs."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/><link href="../assets/benchmarks.css" rel="stylesheet" type="text/css"/><script src="../assets/sa.js" data-collect-dnt="true" async></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">NonuniformFFTs</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">NonuniformFFTs.jl</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../accuracy/">Accuracy</a></li><li class="is-active"><a class="tocitem" href>Benchmarks</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#CPU-CUDA-(H100)"><span>CPU + CUDA (H100)</span></a></li><li><a class="tocitem" href="#CPU-AMDGPU-(MI300A)"><span>CPU + AMDGPU (MI300A)</span></a></li></ul></li><li><a class="tocitem" href="../API/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Benchmarks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Benchmarks</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/jipolanco/NonuniformFFTs.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/jipolanco/NonuniformFFTs.jl/blob/master/docs/src/benchmarks.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Benchmarks"><a class="docs-heading-anchor" href="#Benchmarks">Benchmarks</a><a id="Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarks" title="Permalink"></a></h1><ul><li><a href="#Introduction">Introduction</a></li><li><a href="#CPU-CUDA-(H100)">CPU + CUDA (H100)</a></li><li class="no-marker"><ul><li><a href="#benchmarks-complex-cuda">Complex non-uniform data</a></li><li class="no-marker"><ul><li><a href="#Type-1-transforms">Type-1 transforms</a></li><li><a href="#benchmarks-complex-cuda-type2">Type-2 transforms</a></li></ul></li><li><a href="#Real-non-uniform-data">Real non-uniform data</a></li><li class="no-marker"><ul><li><a href="#Type-1-transforms-2">Type-1 transforms</a></li><li><a href="#Type-2-transforms">Type-2 transforms</a></li></ul></li><li><a href="#FINUFFT-set-up">FINUFFT set-up</a></li></ul></li><li><a href="#CPU-AMDGPU-(MI300A)">CPU + AMDGPU (MI300A)</a></li><li class="no-marker"><ul><li><a href="#Complex-non-uniform-data">Complex non-uniform data</a></li><li class="no-marker"><ul><li><a href="#Type-1-transforms-3">Type-1 transforms</a></li><li><a href="#Type-2-transforms-2">Type-2 transforms</a></li></ul></li><li><a href="#Real-non-uniform-data-2">Real non-uniform data</a></li><li class="no-marker"><ul><li><a href="#Type-1-transforms-4">Type-1 transforms</a></li><li><a href="#Type-2-transforms-3">Type-2 transforms</a></li></ul></li></ul></li></ul><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>The benchmarks consist in type-1 and type-2 NUFFTs on a uniform 3D grid of fixed dimensions <span>$M^3 = 256^3$</span> (excluding oversampling). We vary the number of non-uniform points <span>$N$</span>, so that the point density <span>$ρ = N / M^3$</span> takes values between <span>$10^{-4}$</span> (very few points) and <span>$10^1$</span> (very dense). Points are randomly located in <span>$[0, 2π)^3$</span> using a uniform distribution. The relative tolerance is fixed to <span>$10^{-6}$</span>. In NonuniformFFTs.jl, this can be achieved with the parameters <code>σ = 1.5</code> (oversampling factor) and <code>m = HalfSupport(4)</code> (see <a href="../accuracy/#accuracy">Accuracy</a>). All tests are run in double precision (<code>Float64</code> or <code>ComplexF64</code> non-uniform data).</p><h2 id="CPU-CUDA-(H100)"><a class="docs-heading-anchor" href="#CPU-CUDA-(H100)">CPU + CUDA (H100)</a><a id="CPU-CUDA-(H100)-1"></a><a class="docs-heading-anchor-permalink" href="#CPU-CUDA-(H100)" title="Permalink"></a></h2><p>The following tests were run on the <a href="http://www.idris.fr/eng/jean-zay/cpu/jean-zay-cpu-hw-eng.html">Jean–Zay supercomputer</a> (IDRIS, CNRS). We run on a compute node equipped with 2 Intel Xeon Platinum 8468 CPUs (96 cores per node) and 4 <strong>Nvidia H100</strong> SXM5 80 GB GPUs. We only used 1/4 of the node, meaning a single GPU and 24 CPU cores.</p><p>The benchmarks compare NonuniformFFTs.jl v0.8.3 (11/07/2025) and FINUFFT v2.4.1 (CPU and GPU; see <a href="#FINUFFT-set-up">FINUFFT set-up</a> for details).</p><p>Each reported time includes (1) the time spent processing non-uniform points (<code>set_points!</code> / <code>(cu)finufft_setpts!</code>) and (2) the time spent on the actual transform (<code>exec_type{1,2}!</code> / <code>(cu)finufft_exec!</code>).</p><p>The script used for benchmarking can be found in <a href="https://github.com/jipolanco/NonuniformFFTs.jl/blob/master/benchmark/CPU+CUDA/run_benchmarks.jl"><code>benchmark/CPU+CUDA/run_benchmarks.jl</code></a>.</p><h3 id="benchmarks-complex-cuda"><a class="docs-heading-anchor" href="#benchmarks-complex-cuda">Complex non-uniform data</a><a id="benchmarks-complex-cuda-1"></a><a class="docs-heading-anchor-permalink" href="#benchmarks-complex-cuda" title="Permalink"></a></h3><p>
Libraries like FINUFFT or NFFT.jl only support complex non-uniform data.
Therefore, these tests provide a direct comparison of the performance of different libraries.
On the CPU (<b>crosses</b>), the performance of the multi-threaded NonuniformFFTs.jl (<span class=NonuniformFFTs>blue</span>) and
FINUFFT (<span class=FINUFFT>orange</span>) implementations is quite comparable over a wide range of problem sizes.
</p><p>On the GPU, we test two different implementations which are heavily inspired by the CuFINUFFT paper (<a href="../#Shih2021">Shih <em>et al.</em>, 2021</a>). The default one (<strong>filled circles</strong>) corresponds to setting <code>gpu_method = :global_memory</code> in <a href="../API/#NonuniformFFTs.PlanNUFFT"><code>PlanNUFFT</code></a>. This method is slightly faster than CuFINUFFT at low point densities, but slightly slower at large ones.</p><p>In fact, at large densities it actually faster to use the non-default <code>gpu_method = :shared_memory</code> option (<strong>open circles</strong>, labelled &quot;SM&quot; in the figures). The <code>:shared_memory</code> method performs some operations on GPU <a href="https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/">shared memory</a> (also called <a href="https://rocm.docs.amd.com/projects/HIP/en/latest/understand/hardware_implementation.html#local-data-share">local data share</a>), which is small but much faster than the GPU&#39;s global memory. During spreading (type-1 transforms), this approach allows to reduce the number of atomic operations performed in global memory. Our implementation is inspired by the CuFINUFFT one (<a href="../#Shih2021">Shih <em>et al.</em>, 2021</a>) with a few differences. In particular, we completely avoid atomic operations on shared memory, which seems to speed up things quite a bit and might explain the important gains with respect to the CuFINUFFT implementation.<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> We also provide a shared-memory implementation of type-2 transforms (interpolation). As seen <a href="#benchmarks-complex-cuda-type2">below</a>, this can enable some minor gains at large point densities.</p><h4 id="Type-1-transforms"><a class="docs-heading-anchor" href="#Type-1-transforms">Type-1 transforms</a><a id="Type-1-transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Type-1-transforms" title="Permalink"></a></h4><img width="100%" src="../img/CUDA/benchmark_ComplexF64_type1_atomics.svg"><h4 id="benchmarks-complex-cuda-type2"><a class="docs-heading-anchor" href="#benchmarks-complex-cuda-type2">Type-2 transforms</a><a id="benchmarks-complex-cuda-type2-1"></a><a class="docs-heading-anchor-permalink" href="#benchmarks-complex-cuda-type2" title="Permalink"></a></h4><img width="100%" src="../img/CUDA/benchmark_ComplexF64_type2_atomics.svg"><h3 id="Real-non-uniform-data"><a class="docs-heading-anchor" href="#Real-non-uniform-data">Real non-uniform data</a><a id="Real-non-uniform-data-1"></a><a class="docs-heading-anchor-permalink" href="#Real-non-uniform-data" title="Permalink"></a></h3><p>These tests are of interest for applications where <strong>non-uniform data is real-valued</strong> (imaginary part is zero). In NonuniformFFTs.jl, this enables the use of real-to-complex (type-1) and complex-to-real (type-2) FFTs and also allows to halve the amount of data processed during the spreading (type-1) and interpolation (type-2) procedures. The benchmarks showcase the important gains which can be obtained by using real-data transforms, which are not available in other libraries like FINUFFT or NFFT.jl.</p><p>In the plots below, the (Cu)FINUFFT curves are exactly the same as in the <a href="#benchmarks-complex-cuda">complex-data</a> benchmarks.</p><h4 id="Type-1-transforms-2"><a class="docs-heading-anchor" href="#Type-1-transforms-2">Type-1 transforms</a><a class="docs-heading-anchor-permalink" href="#Type-1-transforms-2" title="Permalink"></a></h4><img width="100%" src="../img/CUDA/benchmark_Float64_type1_atomics.svg"><h4 id="Type-2-transforms"><a class="docs-heading-anchor" href="#Type-2-transforms">Type-2 transforms</a><a id="Type-2-transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Type-2-transforms" title="Permalink"></a></h4><img width="100%" src="../img/CUDA/benchmark_Float64_type2_atomics.svg"><h3 id="FINUFFT-set-up"><a class="docs-heading-anchor" href="#FINUFFT-set-up">FINUFFT set-up</a><a id="FINUFFT-set-up-1"></a><a class="docs-heading-anchor-permalink" href="#FINUFFT-set-up" title="Permalink"></a></h3><p>We used FINUFFT via its Julia wrapper <a href="https://github.com/ludvigak/FINUFFT.jl">FINUFFT.jl</a> v3.4.0. For performance reasons, the (Cu)FINUFFT libraries were compiled locally and the FINUFFT.jl sources were modified accordingly as described <a href="https://github.com/ludvigak/FINUFFT.jl?tab=readme-ov-file#advanced-installation-and-locally-compiling-binaries">here</a>. FINUFFT was compiled using Nvidia&#39;s <code>nvc++</code> CPU compiler using CMake with its default flags in <code>Release</code> mode. For CuFINUFFT, we set <code>CMAKE_CUDA_ARCHITECTURES=90</code> (for an NVIDIA H100) and used the <code>nvcc</code> compiler included in CUDA 12.8.</p><p>All FINUFFT benchmarks were run with relative tolerance <code>1e-6</code>. Moreover, the following options were used:</p><ul><li><code>modeord = 1</code> (use FFTW ordering, for consistency with NonuniformFFTs)</li><li><code>spread_sort = 1</code> (enable point sorting in CPU plans)</li><li><code>spread_kerevalmeth = 1</code> (use the recommended piecewise polynomial evaluation)</li><li><code>fftw = FFTW.ESTIMATE</code> (CPU plans)</li></ul><p>and for GPU plans:</p><ul><li><code>gpu_sort = 1</code> (enable point sorting)</li><li><code>gpu_kerevalmeth = 1</code> (use piecewise polynomial evaluation)</li><li><code>gpu_method = 1</code> (global memory method, &quot;non-uniform points driven&quot;)</li></ul><p>We also tried <code>gpu_method = 2</code> (open symbols, labelled SM) which seems to be considerably slower in nearly all cases (in three dimensions, at the requested tolerance).</p><h2 id="CPU-AMDGPU-(MI300A)"><a class="docs-heading-anchor" href="#CPU-AMDGPU-(MI300A)">CPU + AMDGPU (MI300A)</a><a id="CPU-AMDGPU-(MI300A)-1"></a><a class="docs-heading-anchor-permalink" href="#CPU-AMDGPU-(MI300A)" title="Permalink"></a></h2><p>NonuniformFFTs.jl also runs on other GPU platforms such as AMD GPUs. The following tests were run on the <a href="https://www.cines.fr/calcul/adastra/">Adastra supercomputer</a> (CINES). We run on a compute node equipped with 4 <strong>AMD Instinct MI300A</strong> accelerators. Each card comes with 24 CPU cores and a GPU. We only used 1/4 of the node, meaning a single MI300A card.</p><p>The benchmarks compare NonuniformFFTs.jl v0.8.3 (11/07/2025) and FINUFFT v2.4.1 (CPU only, using Cray compilers).</p><p>Each reported time includes (1) the time spent processing non-uniform points (<code>set_points!</code> / <code>(cu)finufft_setpts!</code>) and (2) the time spent on the actual transform (<code>exec_type{1,2}!</code> / <code>(cu)finufft_exec!</code>).</p><p>The script used for benchmarking can be found in <a href="https://github.com/jipolanco/NonuniformFFTs.jl/blob/master/benchmark/CPU+AMDGPU/run_benchmarks.jl"><code>benchmark/CPU+AMDGPU/run_benchmarks.jl</code></a>.</p><p>The CPU tests shown below used the <code>use_atomics = true</code> option of <a href="../API/#NonuniformFFTs.PlanNUFFT"><code>PlanNUFFT</code></a>, as the alternative really degraded performance of type-1 transforms in that machine. Full results with the two variants are available in <a href="https://github.com/jipolanco/NonuniformFFTs.jl/blob/master/benchmark/CPU+AMDGPU/plots">this directory</a>.</p><p>As can be seen below, compared to CUDA, on AMDGPU the <code>gpu_method = :shared_memory</code> (SM) option becomes faster than the default at relatively low point densities, while the default <code>:global_memory</code> option scales very poorly for a large number of points. This is something to take into account when using NonuniformFFTs.jl on AMD GPUs.</p><h3 id="Complex-non-uniform-data"><a class="docs-heading-anchor" href="#Complex-non-uniform-data">Complex non-uniform data</a><a id="Complex-non-uniform-data-1"></a><a class="docs-heading-anchor-permalink" href="#Complex-non-uniform-data" title="Permalink"></a></h3><h4 id="Type-1-transforms-3"><a class="docs-heading-anchor" href="#Type-1-transforms-3">Type-1 transforms</a><a class="docs-heading-anchor-permalink" href="#Type-1-transforms-3" title="Permalink"></a></h4><img width="100%" src="../img/AMDGPU/benchmark_ComplexF64_type1_atomics.svg"><h4 id="Type-2-transforms-2"><a class="docs-heading-anchor" href="#Type-2-transforms-2">Type-2 transforms</a><a class="docs-heading-anchor-permalink" href="#Type-2-transforms-2" title="Permalink"></a></h4><img width="100%" src="../img/AMDGPU/benchmark_ComplexF64_type2_atomics.svg"><h3 id="Real-non-uniform-data-2"><a class="docs-heading-anchor" href="#Real-non-uniform-data-2">Real non-uniform data</a><a class="docs-heading-anchor-permalink" href="#Real-non-uniform-data-2" title="Permalink"></a></h3><h4 id="Type-1-transforms-4"><a class="docs-heading-anchor" href="#Type-1-transforms-4">Type-1 transforms</a><a class="docs-heading-anchor-permalink" href="#Type-1-transforms-4" title="Permalink"></a></h4><img width="100%" src="../img/AMDGPU/benchmark_Float64_type1_atomics.svg"><h4 id="Type-2-transforms-3"><a class="docs-heading-anchor" href="#Type-2-transforms-3">Type-2 transforms</a><a class="docs-heading-anchor-permalink" href="#Type-2-transforms-3" title="Permalink"></a></h4><img width="100%" src="../img/AMDGPU/benchmark_Float64_type2_atomics.svg"><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>The CuFINUFFT shared-memory implementation might perform better (relative to the global-memory method) for two-dimensional or low-accuracy problems.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../accuracy/">« Accuracy</a><a class="docs-footer-nextpage" href="../API/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 18 August 2025 08:50">Monday 18 August 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
